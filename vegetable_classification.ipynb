{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIHjJCB5HWa2"
   },
   "source": [
    "# Vegetable Classification\n",
    "[Original Kaggle Notebook](https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset)\n",
    "\n",
    "* Classify 15 different types of vegetables using transfer learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9m2CQyQjkC4"
   },
   "source": [
    "# Import data and helper documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OiOHx3dCqVZL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "znGC83iyjJF2",
    "outputId": "1b046db6-fd92-44d6-eeb7-5cef41bcec84"
   },
   "outputs": [],
   "source": [
    "list_dir = os.listdir('.')\n",
    "\n",
    "if 'vegetable-images.zip?dl=0' not in list_dir:\n",
    "  # fetch images\n",
    "  !wget https://www.dropbox.com/s/lbqzfovdqs02nr8/vegetable-images.zip?dl=0\n",
    "  # fetch helper documents\n",
    "  !wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_S_ZWNP1BAlY"
   },
   "outputs": [],
   "source": [
    "# Let's create a function tgo compare training histories\n",
    "def compare_histories(original_history, new_history, initial_epochs=5):\n",
    "  \"\"\"\n",
    "  Compares two TensorFlow History Objects\n",
    "  \"\"\"\n",
    "\n",
    "  # Get original history measurements\n",
    "  acc = original_history.history['accuracy']\n",
    "  loss = original_history.history['loss']\n",
    "  \n",
    "  val_acc = original_history.history['val_accuracy']\n",
    "  val_loss = original_history.history['val_loss']\n",
    "\n",
    "  # Combine original history metrics with new history metrics\n",
    "  total_acc = acc + new_history.history['accuracy']\n",
    "  total_loss = loss + new_history.history['loss']\n",
    "  \n",
    "  total_val_acc = val_acc + new_history.history['val_accuracy'] \n",
    "  total_val_loss = val_loss + new_history.history['val_loss']\n",
    "\n",
    "  # Make plot for accuracy\n",
    "  plt.figure(figsize=(8,8))\n",
    "\n",
    "  plt.subplot(2, 1, 1)\n",
    "  plt.plot(total_acc, label='Trainig Acc')\n",
    "  plt.plot(total_val_acc, label='Validation Accuracy')\n",
    "  plt.plot([initial_epochs-1, initial_epochs-1], plt.ylim(), label='Start Fine Tuning')\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.title('Training and validation accuracy')\n",
    "\n",
    "  # Make plot for loss\n",
    "  plt.figure(figsize=(8,8))\n",
    "\n",
    "  plt.subplot(2, 1, 2)\n",
    "  plt.plot(total_loss, label='Trainig Loss')\n",
    "  plt.plot(total_val_loss, label='Validation loss')\n",
    "  plt.plot([initial_epochs-1, initial_epochs-1], plt.ylim(), label='Start Fine Tuning')\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.title('Training and validation loss')\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-87TjHnVo7xZ"
   },
   "outputs": [],
   "source": [
    "from helper_functions import plot_loss_curves, unzip_data, walk_through_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pW47U5japJQ5"
   },
   "outputs": [],
   "source": [
    "\n",
    "dir_list = os.listdir('.')\n",
    "\n",
    "# unzip data if docs don't exist yet\n",
    "if 'train_30' not in dir_list:\n",
    "  unzip_data('vegetable-images.zip?dl=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0kdSH4kbpT3-",
    "outputId": "223cdeeb-8e62-4f29-9e1e-556f24ba5cdf"
   },
   "outputs": [],
   "source": [
    "# Check some of the directories\n",
    "walk_through_dir('validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vm7DsV3Zshwn"
   },
   "source": [
    "# Preprocess data\n",
    "\n",
    "Lets setup our images and create functions to create new models with the same architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DB40rGnRu4An"
   },
   "source": [
    "## Create image datasets from directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkGFCm6Su8Wx",
    "outputId": "9f2b68c1-a71d-4197-c584-ba3470660fb2"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_30_percent = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  'train_30',\n",
    "  image_size = (224, 224),\n",
    "  label_mode = 'categorical',\n",
    "  seed = 42\n",
    ")\n",
    "\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  'train',\n",
    "  image_size = (224, 224),\n",
    "  label_mode = 'categorical',\n",
    "  seed = 42\n",
    ")\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  'test',\n",
    "  image_size = (224, 224),\n",
    "  label_mode = 'categorical',\n",
    "  seed = 42\n",
    ")\n",
    "\n",
    "validation_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  'validation',\n",
    "  image_size = (224, 224),\n",
    "  label_mode = 'categorical',\n",
    "  seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkCWPKCiuJKh"
   },
   "source": [
    "## Create data augmentation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_zI0syLpavQ"
   },
   "outputs": [],
   "source": [
    "data_augmentation_dial = 0.2\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(data_augmentation_dial),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomZoom(data_augmentation_dial),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomHeight(data_augmentation_dial),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomWidth(data_augmentation_dial),\n",
    "  # tf.keras.layers.experimental.preprocessing.Resizing(224, 224),\n",
    "  # tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "], name='data_augmentation_layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xD8W6Fbt7J7"
   },
   "source": [
    "## Create function to visualize images (normal/augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "vOtcj86VuTdQ",
    "outputId": "81abaad2-5aab-4d32-8c00-d5f365c0fb49"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "# Set random states\n",
    "# random.seed(42)\n",
    "# tf.random.set_seed(42)\n",
    "\n",
    "def view_random_image():\n",
    "  target_class = random.choice(train_data.class_names)\n",
    "  target_dir = 'train/' + target_class\n",
    "  random_image = random.choice(os.listdir(target_dir))\n",
    "  random_image_path = target_dir + '/' + random_image\n",
    "\n",
    "  plt.figure(figsize=(10,15))\n",
    "\n",
    "  # Read in random image\n",
    "  image = mpimg.imread(random_image_path)\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.imshow(image)\n",
    "  plt.title(f'The original random image from class: {target_class}')\n",
    "  plt.axis(False)\n",
    "\n",
    "\n",
    "  # Now plot the augmented random image\n",
    "  augmented_image = data_augmentation(tf.expand_dims(image, axis=0), training=True)\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.imshow(tf.squeeze(augmented_image/255.))\n",
    "  plt.title(f'Augmented Image')\n",
    "  plt.axis(False)\n",
    "\n",
    "view_random_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtVJekkN4g51"
   },
   "source": [
    "## Creating checkpoint callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JU0JhoRi4rG4"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = 'vegetables_checkpoint_30_percent/checkpoint.ckpt'\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights=True,\n",
    "    save_best_only=True,\n",
    "    save_freq='epoch',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtnogswQuii6"
   },
   "source": [
    "# Create Feature Extraction models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-D2Bak2xN8h"
   },
   "source": [
    "## Feature Extraction base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdEB77yJxIJe"
   },
   "outputs": [],
   "source": [
    "from numpy import e\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "# Setup input shape and base model\n",
    "input_shape = (224, 224, 3)\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create input layer\n",
    "inputs = layers.Input(shape=input_shape, name = 'input_layer')\n",
    "\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Extract features from model\n",
    "x = layers.GlobalAveragePooling2D (name='global_average_pooling_layer')(x)\n",
    "\n",
    "outputs = layers.Dense(15, activation='softmax', name='output_layer')(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWzALNR5yMMu"
   },
   "source": [
    "## Model 1: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YB8UgJbdyWZK",
    "outputId": "69577063-49bf-46d6-a997-e0940352b3ab"
   },
   "outputs": [],
   "source": [
    "\n",
    "model_1 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model_1.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "initial_epochs = 5\n",
    "history_1 = model_1.fit(\n",
    "    train_30_percent, \n",
    "    epochs = initial_epochs,\n",
    "    steps_per_epoch=len(train_30_percent),\n",
    "    validation_data=validation_data,\n",
    "    validation_steps=len(validation_data),\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "plot_loss_curves(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "heBxobonzOPG",
    "outputId": "b9160b3a-6c6c-4e0e-abdb-29de1e5bb2f5"
   },
   "outputs": [],
   "source": [
    "model_1_results = model_1.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-G_rjj500OV"
   },
   "source": [
    "* model_1 gives great results with 99% accuracy on the full test dataset\n",
    "* model_1 only uses 30% of training data, we'll use the full training set once we fine tune the model\n",
    "\n",
    "Since model_1 has good performance we'll checkpoint it to create the fine tuned models to squeeze a little more out of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veycdSxJ2wL1"
   },
   "source": [
    "## Model 2: Fine tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KO4qI_c23Fp-",
    "outputId": "e80a3e99-e749-4573-def1-829a1eb17404"
   },
   "outputs": [],
   "source": [
    "# Load in the model\n",
    "model_2 = tf.keras.Model(inputs, outputs)\n",
    "model_2.load_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iVQPGOI7pYf"
   },
   "source": [
    "### Unfreeze layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tN69Offy9vSv"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Freeze all layers except the last 10\n",
    "for layer in base_model.layers[:-10]:\n",
    "  layer.trainable = False\n",
    "\n",
    "\n",
    "# Recompile (We have to recompile our models every time we make a change)\n",
    "model_2.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  # When fine tuning, you typically want to lower the learning rate by 10X\n",
    "  optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMdbHOp3-I8X"
   },
   "outputs": [],
   "source": [
    "# Check which layers are trainable\n",
    "for layer_number, layer in enumerate(model_2.layers[2].layers):\n",
    "  print(layer_number, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PM3I3CO_6hD"
   },
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "id": "n8NjAl2nAV1S",
    "outputId": "203068ea-4966-4db3-e92d-52bcd73c7e8d"
   },
   "outputs": [],
   "source": [
    "\n",
    "fine_tuned_epochs = initial_epochs + 5\n",
    "\n",
    "history_2 = model_2.fit(\n",
    "    test_data,\n",
    "    epochs=fine_tuned_epochs,\n",
    "    steps_per_epoch=len(test_data),\n",
    "    validation_data=validation_data,\n",
    "    validation_steps = len(validation_data),\n",
    "    initial_epoch=history_1.epoch[-1]\n",
    ")\n",
    "\n",
    "compare_histories(history_1, history_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8EAXvZmAZ-e",
    "outputId": "ad9774ec-f256-44ca-d411-6e87cda46e93"
   },
   "outputs": [],
   "source": [
    "model_2_results = model_2.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ksBL_ZSLBp3r",
    "outputId": "a3f22e49-fa20-44e3-bfeb-c579f479ccaa"
   },
   "outputs": [],
   "source": [
    "model_1_results, model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Av4urVJeBwFh"
   },
   "source": [
    "* unfreezing some layers gave us a higher percentage although it's already high from model_1\n",
    "\n",
    "lets try one more time and we'll unfreeze more layers (30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvclBeX6CBZq"
   },
   "source": [
    "## Model 3: Unfreeze more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s39TxnK9CEW2",
    "outputId": "71d6772c-2e70-4814-b82a-6a72bf4b2885"
   },
   "outputs": [],
   "source": [
    "model_3 = tf.keras.Model(inputs, outputs)\n",
    "model_3.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWvqCwmqCNcz"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Freeze all layers except the last 30\n",
    "for layer in base_model.layers[:-30]:\n",
    "  layer.trainable = False\n",
    "\n",
    "\n",
    "# Recompile (We have to recompile our models every time we make a change)\n",
    "model_3.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  # When fine tuning, you typically want to lower the learning rate by 10X\n",
    "  optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBxBRA9mCjpc"
   },
   "source": [
    "### Fit the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "id": "2spxWgNZC0Mu",
    "outputId": "669e6f0a-559e-4bbd-c320-8bb97efb58fa"
   },
   "outputs": [],
   "source": [
    "fine_tuned_epochs = initial_epochs + 5\n",
    "\n",
    "history_3 = model_3.fit(\n",
    "    test_data,\n",
    "    epochs=fine_tuned_epochs,\n",
    "    steps_per_epoch=len(test_data),\n",
    "    validation_data=validation_data,\n",
    "    validation_steps = len(validation_data),\n",
    "    initial_epoch=history_1.epoch[-1]\n",
    ")\n",
    "\n",
    "compare_histories(history_1, history_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qKGZmeVDScX",
    "outputId": "5f8bdeb8-a7d7-49d4-96cc-923bafb9f5c7"
   },
   "outputs": [],
   "source": [
    "model_3_results = model_3.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IInnzlbcDsol"
   },
   "source": [
    "# Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "UXMPzS53Dzhq",
    "outputId": "4884d9bc-c0b6-449e-b0bb-52b025654893"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = [model_1_results , model_2_results, model_3_results]\n",
    "results_pd = pd.DataFrame(results, columns=['loss', 'accuracy'])\n",
    "results_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3JJZOEPD6gj"
   },
   "source": [
    "# Summary\n",
    "\n",
    "from the start `EfficientNetB0` habe us a very high score with only 30% of the traning data_augmentation\n",
    "\n",
    "`model_3` gives us the best accuracy score with 30 layers of the base model unfrozen and re-fitted on our custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l82cq5gmEqo2",
    "outputId": "82d67674-8814-4627-e3cf-ee2c465e98db"
   },
   "outputs": [],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tofcm2orEr2f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of vegetables-classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
